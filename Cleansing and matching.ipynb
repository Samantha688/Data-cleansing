{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a38540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.zip[ind] = df.zip[ind].split('.', 1)[0] #remove .0 after zip\n",
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.zip[ind] = df.zip[ind].strip(' ') #remove spaces before and after\n",
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.address[ind] = result\n",
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['address'][ind] = df['fuzzy match'][ind]\n",
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.zip[ind] = df.zip[ind].split('.', 1)[0] #remove .0 after zip\n",
      "/var/folders/9z/0pvw3fjs5bj17s3vcxnxzn1r0000gn/T/ipykernel_1427/3162532924.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.zip[ind] = df.zip[ind].strip(' ') #remove spaces before and after\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new coverage:  1.0\n",
      "prior coverage:  0.36666666666666664\n",
      "    index  uid                    address           city state    zip\n",
      "0       0    1         1114 Mt George Ave           Napa    CA  94558\n",
      "1       1    2         5429 W Slauson Ave    Los Angeles    CA  90056\n",
      "2       2    3              1213 Court St        Alameda    CA  94501\n",
      "3       3    4            7707 Jayseel St    Los Angeles    CA  91042\n",
      "4       4    5           12273 Mulhall St       El Monte    CA  91732\n",
      "5       5    6                 17 21st St     Greenville    PA  16125\n",
      "6       6   10              1699 Lunt Ave    Des Plaines    IL  60018\n",
      "7       7   11              631 N 21st St       San Jose    CA  95112\n",
      "8       8   12           18309 3rd Ave NW      Shoreline    WA  98177\n",
      "9       9   15         1608 N Comstock Ct        Visalia    CA  93292\n",
      "10     10   16            6170 Alvord Way     Pleasanton    CA  94588\n",
      "11     11   17           2670 BERNWOOD ST         Duarte    CA  91010\n",
      "12     12   19             130 Park Pl Dr     Georgetown    TX  78628\n",
      "13     13   20         2531 Manhatten Ave        Thermal    CA  92274\n",
      "14     14   24            398 Dolliver St    Pismo Beach    CA  93449\n",
      "15     15   25     9512 Chicory Field Way      Elk Grove    CA  95624\n",
      "16     16   26         1620 New Jersey St    Los Angeles    CA  90033\n",
      "17     17   28       3671 Happy Valley Rd      Lafayette    CA  94549\n",
      "18     18   31          6955 Peachtree Rd       Carlsbad    CA  92011\n",
      "19     19   32              2420 Fern Trl          Sunol    CA  94586\n",
      "20     20   34  41544 Avenida De La Reina       Temecula    CA  92592\n",
      "21     21   35          1863 Channing Ave      Palo Alto    CA  94303\n",
      "22     22   37              1615 183rd St        Gardena    CA  90248\n",
      "23     23   39   28380 Burrough Valley Rd      Tollhouse    CA  93667\n",
      "24     24   42         152 N Mariposa Ave    Los Angeles    CA  90004\n",
      "25     25   44        5400 Playa Vista Dr    Los Angeles    CA  90094\n",
      "26     26   46           14031 Astoria St    Los Angeles    CA  91342\n",
      "27     27   48              1061 Derby Ct        Manteca    CA  95336\n",
      "28     28   49              646 Lemon Way       Fillmore    CA  93015\n",
      "29     29   50       26177 Charismatic Ct  Moreno Valley    CA  92555\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fuzzywuzzy\n",
    "import thefuzz\n",
    "from thefuzz import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import pickle\n",
    "from csv import DictWriter\n",
    "\n",
    "def readfile(filename):\n",
    "    df = pd.read_csv('/Users/samanthalee/Desktop/csv/' + filename +'.csv')\n",
    "    return df\n",
    "\n",
    "def check(df):\n",
    "    print(df.head())\n",
    "    print(df.dtypes)\n",
    "    \n",
    "#function for cleaning zip col from test file \n",
    "def clean(df):\n",
    "    df.zip = df.zip.astype(str) #turning zip into string\n",
    "    for ind in df.index: \n",
    "        df.zip[ind] = df.zip[ind].split('.', 1)[0] #remove .0 after zip \n",
    "        df.zip[ind] = df.zip[ind].strip(' ') #remove spaces before and after \n",
    "\n",
    "#function for replacing address with close match\n",
    "def replace_with_fuzzy_match(test, standard, threshold):\n",
    "    test_cleaned = [x for x in test[\"address\"] if not(pd.isnull(x))]\n",
    "    standard_cleaned = [x for x in standard[\"address\"].unique() if not(pd.isnull(x))]\n",
    "    tuples_list = [max([(fuzz.ratio(i,j),j) for j in standard_cleaned]) for i in test_cleaned]\n",
    "    similarity_score, fuzzy_match = map(list,zip(*tuples_list))\n",
    "    df = pd.DataFrame({\"list_A\":test_cleaned, \"fuzzy match\": fuzzy_match, \"similarity score\": similarity_score})\n",
    "    for ind in test.index:\n",
    "        if df['similarity score'][ind] >= threshold:\n",
    "            test['address'][ind] = df['fuzzy match'][ind]\n",
    "    return test\n",
    "\n",
    "#function for mapping dictionary to missing values \n",
    "def map_to_dict(test, column):\n",
    "    with open('/Users/samanthalee/Desktop/' + column +'.pkl', 'rb') as fp:\n",
    "        x = pickle.load(fp)\n",
    "        test[column] = test[column].fillna(test['address'].map(x))\n",
    "\n",
    "#function for combining address, state, city, zip col in test datasets for matching      \n",
    "def combine_test(df):\n",
    "    df_combine = df.address + df.state + df.city + df.zip \n",
    "    df_combine = df_combine.dropna()\n",
    "    df_combine = df_combine.to_frame()\n",
    "    return df_combine\n",
    "\n",
    "#function for calculating coverage ratios\n",
    "def merge_and_calculate(test_combine, standard_combine):\n",
    "    join = pd.merge(standard_combine, test_combine, how = 'inner') \n",
    "    coverage = join.shape[0]/original_row \n",
    "    return join.shape[0],coverage \n",
    "\n",
    "#read files\n",
    "df_test = readfile('test')\n",
    "df_all = readfile('all_addresses')\n",
    "\n",
    "#calculate deniminator for coverage ratio \n",
    "original_row = df_test.shape[0]\n",
    "\n",
    "#creating test file copy for calculating previous coverage ratio \n",
    "df_test2 = df_test.copy()\n",
    "clean(df_test2)\n",
    "\n",
    "#clean test dataset\n",
    "for ind in df_test.index: \n",
    "    result = df_test.address[ind].split(',', 1)[0] \n",
    "    df_test.address[ind] = result\n",
    "df_test['state'] = df_test['state'].str.upper() #turning all state into uppercase\n",
    "df_test = df_test.drop(df_test[df_test[\"address\"].str.contains(\"#NAM\")].index) \n",
    "#drop rows where address contains \n",
    "#NAM since they can never be matched \n",
    "df_test = df_test.reset_index()\n",
    "\n",
    "#clean standard dataset\n",
    "df_all = df_all.dropna() #remove NaN rows \n",
    "df_all = df_all[df_all.address != '#NAME?'] #remove rows containing #NAME?\n",
    "\n",
    "#replacing test file with close match using fuzzywuzzy\n",
    "#setting threshold as 80%, i.e. only matches > 80% is considered as wrong entry, < 80% is considered as a different entry\n",
    "df_test = replace_with_fuzzy_match(df_test, df_all, 80)\n",
    "\n",
    "#using dictionary created from standard datasets to map missing values in zip, state and city columns         \n",
    "map_to_dict(df_test, 'zip')\n",
    "map_to_dict(df_test, 'state')\n",
    "map_to_dict(df_test, 'city')\n",
    "\n",
    "#clean new test file for merging \n",
    "clean(df_test)\n",
    "\n",
    "#combining address, state, city, zip col in standard dataset for matching \n",
    "standard_combine = df_all.address + df_all.state + df_all.city + df_all.zip \n",
    "standard_combine = standard_combine.drop_duplicates() \n",
    "standard_combine = standard_combine.to_frame()\n",
    "\n",
    "#combining address, state, city, zip col in test dataset for matching \n",
    "test_combine = combine_test(df_test)\n",
    "test2_combine = combine_test(df_test2)\n",
    "\n",
    "#calculating coverage ratio \n",
    "print('new coverage: ', merge_and_calculate(test_combine, standard_combine)[1])\n",
    "print('prior coverage: ', merge_and_calculate(test2_combine, standard_combine)[1])\n",
    "print(df_test)\n",
    "\n",
    "#appending merged row into one csv file\n",
    "field_names = ['coverage']\n",
    "dict = {'coverage': merge_and_calculate(test_combine, standard_combine)[0]}\n",
    "\n",
    "with open('/Users/samanthalee/Desktop/total.csv', 'a') as f_object:\n",
    "    dictwriter_object = DictWriter(f_object, fieldnames=field_names)\n",
    "    dictwriter_object.writerow(dict)\n",
    "    f_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c4451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
